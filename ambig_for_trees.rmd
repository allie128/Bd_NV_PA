---
title: "PA_NV_ambig_seq_analysis_for_tree"
output: github_document
editor_options: 
  chunk_output_type: console
---

Let's load the libraries we will need

```{r setup, include=FALSE}
library(knitr)
library(Biostrings)
library(tidyverse)
library(muscle)
library(filesstrings)

```

First, we list files corresponding to the ambiguities sequences for each sample. There is a separate folder for each group of samples.

```{r}

#Now let's list the files in that folder
files_PA <- list.files("./PA_ambig_final_for_waddle_serdp", full.names = T)
files_NV <- list.files("./NV_ambig_final_for_waddle_serdp", full.names = T)
files_ref <- list.files("./PA_ambig_final_for_waddle_serdp", full.names = T)

```


Now let's see how many sequences we have for each primer/sample. This is calculated separately for each dataset (PA and NV)

```{r}
#make empty objects
length_table_PA <- tibble(sample = "", length=0, file="")
length_table_NV <- tibble(sample = "", length=0, file="")

#extract sample names
samplenames_PA <- sapply(files_PA, function(x)unlist(strsplit(x,split=".fasta_primerfix.fasta_trim"))[1])
samplenames_PA <- sapply(samplenames_PA, function(x) unlist(strsplit(x, split="Sample."))[2])

samplenames_NV <- sapply(files_NV, function(x)unlist(strsplit(x,split=".fasta_primerfix.fasta_trim"))[1])
samplenames_NV <- sapply(samplenames_NV, function(x) unlist(strsplit(x, split="Sample."))[2])

#count number of sequences per sample

#for PA
for (i in 1: length(files_PA)){
    seq <- readDNAStringSet(files_PA[i], format = "fasta")
    length_table_PA <- add_row(length_table_PA, sample=samplenames_PA[i], length=length(seq), file=files_PA[i])
}

#for NV
for (i in 1: length(files_NV)){
    seq <- readDNAStringSet(files_NV[i], format = "fasta")
    length_table_NV <- add_row(length_table_NV, sample=samplenames_NV[i], length=length(seq), file=files_NV[i])
}

#plot the results
par(mfrow=c(2,1))
hist(as.numeric(length_table_PA$length[-1]), breaks=50, main="PA")
hist(as.numeric(length_table_NV$length[-1]), breaks=50, main="NV")

#get list of only samples with at least 50 sequences 
files_PA_90 <- filter(length_table_PA, length>50)
filenames_PA_90 <- files_PA_90$file
length(filenames_PA_90)

files_NV_90 <- filter(length_table_NV, length>50)
filenames_NV_90 <- files_NV_90$file
length(filenames_NV_90)

#get list that includes all samples with at least 50 sequences from both NV and PA (and the refs too)

files_all_90 <- bind_rows(files_PA_90, files_NV_90)
#remove duplicate reference samples
files_all_90 <- files_all_90[-c(1:13),]
filenames_all_90 <- files_all_90$file
length(filenames_all_90)

```

Now that we have the samples selected, let's fill in a matrix m with the sequences. Each row is a sample and each column is a locus.

```{r}
#make empty matrix of the right size for each dataset
m_PA <-matrix(NA, nrow=nrow(files_PA_90), ncol=243)
colnames(m_PA) <- seq(1,243)
rownames(m_PA) <- files_PA_90$sample
seq_matrix <- as_tibble(m_PA)

m_NV <-matrix(NA, nrow=nrow(files_NV_90), ncol=243)
colnames(m_NV) <- seq(1,243)
rownames(m_NV) <- files_NV_90$sample
seq_matrix <- as_tibble(m_NV)

m_all <- matrix(NA, nrow=nrow(files_all_90), ncol=243)
colnames(m_all) <- seq(1,243)
rownames(m_all) <- files_all_90$sample
seq_matrix <- as_tibble(m_all)

#populate the empty matrix with the ambiguities sequences for PA
for (i in 1:length(filenames_PA_90)){
  seq <- readDNAStringSet(filenames_PA_90[i])
  for (j in 1:length(seq)){
    col_match <- as.numeric(names(seq))
    m_PA[i,col_match[j]] <- as.character(seq[j])
     }
}

#populate the empty matrix with the ambiguities sequences for NV
for (i in 1:length(filenames_NV_90)){
  seq <- readDNAStringSet(filenames_NV_90[i])
  for (j in 1:length(seq)){
    col_match <- as.numeric(names(seq))
    m_NV[i,col_match[j]] <- as.character(seq[j])
     }
}

#populate the empty matrix with the ambiguities sequences for the combined dataset
for (i in 1:length(filenames_all_90)){
  seq <- readDNAStringSet(filenames_all_90[i])
  for (j in 1:length(seq)){
    col_match <- as.numeric(names(seq))
    m_all[i,col_match[j]] <- as.character(seq[j])
     }
}

```

Now we have a matrix m with samples as rows and primers as columns. First we can eliminate primers with no data. Let's get the average length of each sequence to determine which has no data. We can also find the min max and mean sequence length to identify potential bad sequences. 

```{r, include=FALSE}
#create an empty object
n_bases_PA <- matrix(NA, nrow=ncol(m_PA), ncol=7)
n_bases_PA[,1] <- colnames(m_PA)

n_bases_NV <- matrix(NA, nrow=ncol(m_NV), ncol=7)
n_bases_NV[,1] <- colnames(m_NV)
  
n_bases_all <- matrix(NA, nrow=ncol(m_all), ncol=7)
n_bases_all[,1] <- colnames(m_all)

#characterize each locus
for (i in 1:ncol(m_PA)){
  n_bases_PA[i,2] <- mean(nchar(m_PA[,i]),na.rm=T)
  n_bases_PA[i,3] <- min(nchar(m_PA[,i]),na.rm=T)
  n_bases_PA[i,4] <- max(nchar(m_PA[,i]),na.rm=T)
  n_bases_PA[i,5] <- median(nchar(m_PA[,i]),na.rm=T)
  n_bases_PA[i,6] <- max(nchar(m_PA[,i]),na.rm=T) - min(nchar(m_PA[,i]),na.rm=T)
  n_bases_PA[i,7] <- sum(is.na(m_PA[,i]))
}

for (i in 1:ncol(m_NV)){
  n_bases_NV[i,2] <- mean(nchar(m_NV[,i]),na.rm=T)
  n_bases_NV[i,3] <- min(nchar(m_NV[,i]),na.rm=T)
  n_bases_NV[i,4] <- max(nchar(m_NV[,i]),na.rm=T)
  n_bases_NV[i,5] <- median(nchar(m_NV[,i]),na.rm=T)
  n_bases_NV[i,6] <- max(nchar(m_NV[,i]),na.rm=T) - min(nchar(m_NV[,i]),na.rm=T)
  n_bases_NV[i,7] <- sum(is.na(m_NV[,i]))
}

for (i in 1:ncol(m_all)){
  n_bases_all[i,2] <- mean(nchar(m_all[,i]),na.rm=T)
  n_bases_all[i,3] <- min(nchar(m_all[,i]),na.rm=T)
  n_bases_all[i,4] <- max(nchar(m_all[,i]),na.rm=T)
  n_bases_all[i,5] <- median(nchar(m_all[,i]),na.rm=T)
  n_bases_all[i,6] <- max(nchar(m_all[,i]),na.rm=T) - min(nchar(m_all[,i]),na.rm=T)
  n_bases_all[i,7] <- sum(is.na(m_all[,i]))
}

colnames(n_bases_PA) <- c("amp","mean","min","max","median","diff","sum")
colnames(n_bases_NV) <- c("amp","mean","min","max","median","diff","sum")
colnames(n_bases_all) <- c("amp","mean","min","max","median","diff","sum")
```

Now let's explore the problem amps. These are ones missing too much data.

```{r}

#identify amps with more than 1/2 missing data - only considering the samples of interest and not the reference samples (hence the +13)
badamps_PA <- which(as.numeric(n_bases_PA[,7]) > (.5*(length(filenames_PA_90)+13)))

badamps_NV <- which(as.numeric(n_bases_NV[,7]) > (.5*(length(filenames_NV_90)+13)))

#find the union so we use the same set of amps for both datasets
badamps_both <- union(badamps_NV, badamps_PA)

m_trim_PA <- m_PA[,-badamps_both]

m_trim_NV <- m_NV[,-badamps_both]

m_trim_all <- m_all[,-badamps_both]

dim(m_trim_PA) 
dim(m_trim_NV)
dim(m_trim_all)

```


For each sample with data, aligns all loci separately. This is done only for the gene tree to species tree approach.

```{r, include=FALSE}
#run once
dir.create("PA_locus_align")
dir.create("NV_locus_align")
dir.create("all_locus_align")

#aligns all seqs (removing those with NAs) and writes them out as a separate fasta into their respective directories 

for (i in 1:ncol(m_trim_PA)){
  locus_list <- m_trim_PA[!is.na(m_trim_PA[,i]),i]
  locus_seq <- DNAStringSet(locus_list)
  locus_align <- muscle::muscle(locus_seq)
  locus_align <- DNAStringSet(locus_align)
  writeXStringSet(locus_align, paste(colnames(m_trim_PA)[i], "_align.fasta", sep=""))
  file.move(paste(colnames(m_trim_PA)[i], "_align.fasta", sep=""), "./PA_locus_align")
}


for (i in 1:ncol(m_trim_NV)){
  locus_list <- m_trim_NV[!is.na(m_trim_NV[,i]),i]
  locus_seq <- DNAStringSet(locus_list)
  locus_align <- muscle::muscle(locus_seq)
  locus_align <- DNAStringSet(locus_align)
  writeXStringSet(locus_align, paste(colnames(m_trim_NV)[i], "_align.fasta", sep=""))
  file.move(paste(colnames(m_trim_NV)[i], "_align.fasta", sep=""), "./NV_locus_align")
}

for (i in 1:ncol(m_trim_all)){
  locus_list <- m_trim_all[!is.na(m_trim_all[,i]),i]
  locus_seq <- DNAStringSet(locus_list)
  locus_align <- muscle::muscle(locus_seq)
  locus_align <- DNAStringSet(locus_align)
  writeXStringSet(locus_align, paste(colnames(m_trim_all)[i], "_align.fasta", sep=""))
  file.move(paste(colnames(m_trim_all)[i], "_align.fasta", sep=""), "./all_locus_align")
}

```

Now for this project I loaded the alignments for each locus into the program geneious. From there I ran raxml for each locus using the following command: 

> raxmlHPC-SSE3-MAC -s input.phy -n output -m GTRCAT -f a -x 1 -N 100 -p 1

Then I exported the resulting consensus tree for each locus alignment. I then used the utility newick-utils to collapse all nodes with >10 bootstrap support using the following comand (with an example tree). First download [newick-utils](https://github.com/tjunier/newick_utils). Then in the command line navigate to the "src" folder in the newick utils program files. Run the following.

> ./nw_ed example_raxml_consensus_locus_tree.newick 'i & b<=10' o > example_raxml_consensus_locus_tree_collapse10.newick

Next I concatenated all newick trees into one file to be input into Astral. In the directory with all the trees (and only the trees) with nodes collapsed I ran the following:

for mac:

> cat * > combined_trees.newick

Finally I ran [Astral](https://github.com/smirarab/ASTRAL) using the set of locus trees with >10 bootstraps collapsed. I ran the following line of code to run Astral:

> java -jar astral.5.6.2.jar -i combined_trees.newick -o combined_ambig.tre 

This outputs your Astral Tree! You can then use newick utils to collapse nodes with low posterior support for display purposes. 



